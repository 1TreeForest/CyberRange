{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "404300ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000.host</td>\n",
       "      <td>1</td>\n",
       "      <td>è®ºååè¡¨ å",
       "¶ä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00ysw.com</td>\n",
       "      <td>1</td>\n",
       "      <td>首页 电影 连续剧 综艺 动漫 更多 &gt; 动作片 喜剧片 爱情片 科幻片 恐怖片 剧情片 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xo.net</td>\n",
       "      <td>1</td>\n",
       "      <td>零零零 首页 無用 归档 搜索&amp;标签 左邻右里 应急储备 到此一游 代码高亮 VP$10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100161.com</td>\n",
       "      <td>1</td>\n",
       "      <td>首页 电影 连续剧 综艺 动漫 资讯 专题 留言 导航 取消 看过 登录 首页 电影 连续...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100fyy.net</td>\n",
       "      <td>1</td>\n",
       "      <td>100分影院 电视剧 电影 动漫 综艺 播出表 首页 电视剧 电影 动漫 综艺 播出表 观...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>zqb.cyol.com</td>\n",
       "      <td>0</td>\n",
       "      <td>中青在线 加入收藏 新闻回顾 检索 中青论坛 广告 首页 中国青年报 打印 关闭</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>zsb.cucn.edu.cn</td>\n",
       "      <td>0</td>\n",
       "      <td>首页 学校简介 校友风采 热点镜头 校园照片 国际交流  观看全景 招考信息 招生资讯...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>zw.liuxue86.com</td>\n",
       "      <td>0</td>\n",
       "      <td>作文 议论文 评论 最新更新 频道地图 九月最值得期待的院线电影 字典 九月最值得期待的院...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>zy3.xidian.edu.cn</td>\n",
       "      <td>0</td>\n",
       "      <td>学校首页 English 首页 书院概况 书院简介 机构设置 团队介绍 书院动态 通知公告...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>zyyjy.bucm.edu.cn</td>\n",
       "      <td>0</td>\n",
       "      <td>首页 组织机构 新闻动态 通知公告 政策文件 资源共享 联系我们     教育部中医学类专...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2252 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 domain  target  \\\n",
       "0            00000.host       1   \n",
       "1             00ysw.com       1   \n",
       "2               0xo.net       1   \n",
       "3            100161.com       1   \n",
       "4            100fyy.net       1   \n",
       "...                 ...     ...   \n",
       "2247       zqb.cyol.com       0   \n",
       "2248    zsb.cucn.edu.cn       0   \n",
       "2249    zw.liuxue86.com       0   \n",
       "2250  zy3.xidian.edu.cn       0   \n",
       "2251  zyyjy.bucm.edu.cn       0   \n",
       "\n",
       "                                                   text  \n",
       "0                                  è®ºååè¡¨ å\n",
       "¶ä...  \n",
       "1      首页 电影 连续剧 综艺 动漫 更多 > 动作片 喜剧片 爱情片 科幻片 恐怖片 剧情片 ...  \n",
       "2      零零零 首页 無用 归档 搜索&标签 左邻右里 应急储备 到此一游 代码高亮 VP$10 ...  \n",
       "3      首页 电影 连续剧 综艺 动漫 资讯 专题 留言 导航 取消 看过 登录 首页 电影 连续...  \n",
       "4      100分影院 电视剧 电影 动漫 综艺 播出表 首页 电视剧 电影 动漫 综艺 播出表 观...  \n",
       "...                                                 ...  \n",
       "2247           中青在线 加入收藏 新闻回顾 检索 中青论坛 广告 首页 中国青年报 打印 关闭  \n",
       "2248     首页 学校简介 校友风采 热点镜头 校园照片 国际交流  观看全景 招考信息 招生资讯...  \n",
       "2249   作文 议论文 评论 最新更新 频道地图 九月最值得期待的院线电影 字典 九月最值得期待的院...  \n",
       "2250   学校首页 English 首页 书院概况 书院简介 机构设置 团队介绍 书院动态 通知公告...  \n",
       "2251   首页 组织机构 新闻动态 通知公告 政策文件 资源共享 联系我们     教育部中医学类专...  \n",
       "\n",
       "[2252 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd_data = pd.read_csv('./movie_raw_data.csv', index_col=0)\n",
    "pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add6cd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\晚秋\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.690 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "# 这段代码是把上面dataframe的text部分进行分词，然后转到列表里面去，方便进行tf-idf，结果可以看下面\n",
    "all_text = []\n",
    "for index in pd_data.index:\n",
    "    item_text = []\n",
    "    text = pd_data.iloc[index, 2]\n",
    "    text = [i for i in text.split()]\n",
    "    for i in text:\n",
    "        for j in jieba.cut(i, cut_all=False):\n",
    "            item_text.append(j)\n",
    "    item_text = ' '.join(item_text)\n",
    "    all_text.append(item_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a0151b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['è ® º å \\x9d \\x9b å \\x88 \\x97 è ¡ ¨ å ¶ ä » \\x96 æ µ \\x8f è § \\x88 å \\x99 ¨ ç \\x94 ¨ æ \\x88 · ä º ¤ æ µ \\x81 é \\x97 ² è \\x81 \\x8a ç \\x81 \\x8c æ ° ´ è ® º å \\x9d \\x9b é \\x82 £ ä ¸ ª ç ½ \\x91 ç \\x9b \\x98 æ ³ ¨ å \\x86 \\x8c é \\x80 \\x81 1T ï ¼ \\x9f å ³ é \\x94 ® æ \\x97 ¶ å \\x88 » 119 æ ± \\x82 å \\x8a © é \\x97 ® ç \\xad \\x94 ç ½ \\x91 ç « \\x99 å » º è ® ® yemo1408 å ½ ± è § \\x86 å \\x88 \\x86 ä º « ç \\x83 \\xad é \\x97 ¨ ç \\x94 µ å ½ ± å \\x8f \\x8d è ´ ª é £ \\x8e æ \\x9a ´ 5 ( 2021 ) q134182528 ç \\x83 \\xad é \\x97 ¨ å \\x89 § é \\x9b \\x86 ç » ´ ä º ¬ ä ¼ å ¥ \\x87 ï ¼ \\x9a è \\x8b ± ç \\x81 µ ç ¥ \\x9e æ ® ¿ q134182528 å ¯ » è § å ½ ± è § \\x86 æ ± \\x82 â \\x80 \\x9c ä ¸ \\x8d ä º \\x8c ç ¥ \\x9e æ \\x8e ¢ â \\x80 \\x9d ç \\x94 µ å ½ ± ï ¼ \\x8c ç £ \\x81 å \\x8a \\x9b ä ¸ \\x8b ä ¸ \\x8d ä º \\x86 ï ¼ \\x8c æ \\x9c \\x89 æ ² ¡ æ \\x9c \\x89 ä ¿ \\x9d å \\xad \\x98 ä º \\x86 ç \\x9a \\x84 å \\x84 å ¼ \\x9f å \\x93 ¦ æ \\x89 \\x91 å \\x8b è \\x84 ¸ è ½ ¯ ä » ¶ å \\x88 \\x86 ä º « ç \\x94 µ è \\x84 \\x91 è ½ ¯ ä » ¶ å ¾ ® è ½ ¯ ç \\x94 µ è \\x84 \\x91 ç ® ¡ å ® ¶ å \\x86 æ µ \\x8b ç \\x89 \\x88 æ \\x89 \\x8b æ \\x9c º è ½ ¯ ä » ¶ TikTok - å \\x8e » å ¹ ¿ å \\x91 \\x8a è § £ é \\x99 ¤ å ° \\x81 é \\x94 \\x81 ç \\x89 \\x88 lzhouh æ º \\x90 ç \\x81 å \\x88 \\x86 ä º « WordPress ä ¸ » é ¢ \\x98 Divi - ä ¼ \\x98 é \\x9b ç \\x9a \\x84 WordPress ä ¸ » é ¢ \\x98 jiyer WordPress æ \\x8f \\x92 ä » ¶ Slider Revolution â \\x80 \\x93 ä ¸ \\x8d ä » ä » æ \\x98 ¯ ä ¸ \\x80 ä ¸ ª WordPress æ » \\x91 å \\x9d \\x97 WHMCS ä ¸ \\x93 å \\x8c º WHMCS - è \\x99 \\x9a æ \\x8b \\x9f ä ¸ » æ \\x9c º è ® ¡ è ´ ¹ å \\x92 \\x8c è \\x87 ª å \\x8a ¨ å \\x8c \\x96 å ¹ ³ å \\x8f ° vdebuger PHP ä ¸ \\x93 å \\x8c º Swipgle - è ½ » æ \\x9d ¾ æ \\x96 \\x87 ä » ¶ ä ¼ è ¾ \\x93 è ® º å \\x9d \\x9b ç ® ¡ ç \\x90 \\x86 è ® º å \\x9d \\x9b å ¬ å \\x91 \\x8a æ \\x9c ¬ ç « \\x99 ä ¸ \\x8b è ½ ½ ç « \\x99 æ \\x9b ´ æ \\x8d ¢ å \\x9c ¨ ç º ¿ ä ¼ \\x9a å \\x91 \\x98 æ \\x9c \\x80 æ \\x96 ° å ¸ \\x96 å \\xad \\x90 Swipgle - è ½ » æ \\x9d ¾ æ \\x96 \\x87 ä » ¶ ä ¼ è ¾ \\x93 PHP ä ¸ \\x93 å \\x8c º å \\x8f \\x8d è ´ ª é £ \\x8e æ \\x9a ´ 5 ( 2021 ) q134182528 ç \\x83 \\xad é \\x97 ¨ ç \\x94 µ å ½ ± æ \\x9c \\x80 æ \\x96 ° è µ \\x84 æ º \\x90 Swipgle - è ½ » æ \\x9d ¾ æ \\x96 \\x87 ä » ¶ ä ¼ è ¾ \\x93 Slider Revolution â \\x80 \\x93 ä ¸ \\x8d ä » ä » æ \\x98 ¯ ä ¸ \\x80 ä ¸ ª WordPress æ » \\x91 å \\x9d \\x97 è \\x81 \\x94 ç ³ » æ \\x88 \\x91 ä » ¬ æ \\x9d ¡ æ ¬ ¾ å \\x92 \\x8c è § \\x84 å \\x88 \\x99 é \\x9a \\x90 ç § \\x81 æ \\x94 ¿ ç \\xad \\x96 å ¸ ® å \\x8a © ä ¸ » é ¡ µ',\n",
       " '首页 电影 连续剧 综艺 动漫 更 多 > 动作片 喜剧片 爱情片 科幻片 恐怖片 剧情片 战争片 谤 法 ： 在 此 矣 幸存者 1937 恐惧 街 2021 切勿 擅动 陌生人 的 善意 2019 第八天 之夜 绝地 狙杀 午夜 2021 杀手 妻子 的 保镖 冥通 银行 特约 ： 翻生 争霸战 盖亚 2021 完美 敌人 2020 更 多 > 泰国 剧 国产 剧 港台剧 日韩剧 欧美 剧 男 文案 撰稿人 ， 要休 育儿 假 我 的 妄想 饭 想得到 夸奖 智子 和 知子 夏日 幽会 玉楼春 逐梦 蓝天 演绎 屋 亲爱 的 爸妈 与 君歌 卫视 版 黑 天鹅湖 大時代 国语 他來 自 江湖 国语 更 多 > 我们 爱上 的 那首歌 ， 新 歌手 明星 许愿池 è ¯ ´ Vival 换乘 恋爱 白种 元 的 国名 饮食 第六感 第二季 做 家务 的 男人 们 第二季 LOUD 超级 乐队 2 期盼 已久 的 大海 赤裸 的 世界史 喜剧 大 联盟 2021 更 多 > 魔 道 祖师 第三季 逆天 至尊 魔 道 祖师 第一季 日语 版 九九八十一 时空 恋人 重生 相逢 ： 给 你 我 的 独家 宠溺 龙王 殿 逆天 邪神 第二季 前无古人 绝世 武神 第三季 元龙 第二季 酷 大叔 的 恋爱 物语 百度 云 影视 杰哥 影视 我 爱 影视 秋秋 影视 全能 影视 人人 影视 返回 首页 返回 顶部']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4c7660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837c8fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=10, max_features=MAX_FEATURES)\n",
    "X_tfidf = tfidf.fit_transform(all_text)\n",
    "X_labels =X_tfidf.toarray() > 0\n",
    "features = tfidf.get_feature_names_out()\n",
    "for index in range(len(X_labels[0])):\n",
    "    if X_labels[0][index] == True:\n",
    "        print(features[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958ac457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '1080p', '2017', '2018', '2019', '2020', '2021', '2022',\n",
       "       '4k', 'app', 'bd', 'com', 'hd', 'icp', 'the', '下载', '专题', '世界',\n",
       "       '中国', '中字', '中心', '企业', '免费', '全部', '全集', '公告', '关于', '剧情', '剧情片',\n",
       "       '动作', '动作片', '动态', '动漫', '动画', '喜剧', '喜剧片', '国产', '国语', '在线', '地图',\n",
       "       '大全', '大陆', '学院', '少年', '工作', '影视', '影院', '恋爱', '恐怖', '恐怖片', '我们',\n",
       "       '手机', '推荐', '故事', '教育', '新闻', '日本', '明星', '更新', '最新', '服务', '查看',\n",
       "       '模板', '欧美', '游戏', '漫画', '热门', '爱情', '爱情片', '王牌', '生活', '电影', '电影网',\n",
       "       '电视剧', '登录', '百度', '直播', '科幻片', '第一季', '第三季', '第二季', '第四季', '纪录片',\n",
       "       '经典', '综艺', '网站', '美国', '联系', '英雄', '蓝光', '观看', '视频', '资源', '资讯',\n",
       "       '软件', '迅雷', '韩国', '音乐', '首页', '高清'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b06b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  2  0]\n",
      " [ 4 71  0 ...  0  1  0]\n",
      " ...\n",
      " [ 1  0  2 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  3  0]\n",
      " [ 0  0  0 ...  0  1  0]]\n",
      "2252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(max_features=MAX_FEATURES)\n",
    "X_count = count.fit_transform(all_text)\n",
    "print(X_count.toarray())\n",
    "print(len(X_count.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfa6449c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '1080p', '2017', '2018', '2019', '2020', '2021', '2022',\n",
       "       '4k', 'app', 'bd', 'com', 'hd', 'icp', 'the', '下载', '专题', '世界',\n",
       "       '中国', '中字', '中心', '企业', '免费', '全部', '全集', '公告', '关于', '剧情', '剧情片',\n",
       "       '动作', '动作片', '动态', '动漫', '动画', '喜剧', '喜剧片', '国产', '国语', '在线', '地图',\n",
       "       '大全', '大陆', '学院', '少年', '工作', '影视', '影院', '恋爱', '恐怖', '恐怖片', '我们',\n",
       "       '手机', '推荐', '故事', '教育', '新闻', '日本', '明星', '更新', '最新', '服务', '查看',\n",
       "       '模板', '欧美', '游戏', '漫画', '热门', '爱情', '爱情片', '王牌', '生活', '电影', '电影网',\n",
       "       '电视剧', '登录', '百度', '直播', '科幻片', '第一季', '第三季', '第二季', '第四季', '纪录片',\n",
       "       '经典', '综艺', '网站', '美国', '联系', '英雄', '蓝光', '观看', '视频', '资源', '资讯',\n",
       "       '软件', '迅雷', '韩国', '音乐', '首页', '高清'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ce782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(X_tfidf.toarray(), pd_data.target.values, test_size=0.2)\n",
    "X_train_ct, X_test_ct, y_train_ct, y_test_ct = train_test_split(X_count.toarray(), pd_data.target.values, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e14cb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def test_models(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "#     if method == 'tfidf':\n",
    "#         X_train = tfidf.transform(X_train)\n",
    "#         X_test = tfidf.transform(X_test)\n",
    "#     elif method == 'count':\n",
    "#         X_train = count.transform(X_train)\n",
    "#         X_test = count.transform(X_test)\n",
    "\n",
    "    model1 = MultinomialNB()\n",
    "    model1.fit(X_train, y_train)\n",
    "    print('Naive_bayes: {:.2f} '.format(model1.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "\n",
    "    model2 = KNeighborsClassifier()\n",
    "    model2.fit(X_train, y_train)\n",
    "    print('kneighbors: {:.2f}'.format(model2.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "    model3 = LogisticRegression()\n",
    "    model3.fit(X_train, y_train)\n",
    "    print('LogisticRegression: {:.2f}'.format(model3.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "    model4 = RandomForestClassifier()\n",
    "    model4.fit(X_train, y_train)\n",
    "    print('RandomForest: {:.2f}'.format(model4.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "    model5 = DecisionTreeClassifier()\n",
    "    model5.fit(X_train, y_train)\n",
    "    print('DecisionTree: {:.2f}'.format(model5.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "    model6 = GradientBoostingClassifier()\n",
    "    model6.fit(X_train, y_train)\n",
    "    print('GradientBoost: {:.2f}'.format(model6.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "    model7 = SVC(kernel='rbf')\n",
    "    model7.fit(X_train, y_train)\n",
    "    print('SVM: {:.2f}'.format(model7.score(X_test, y_test)))\n",
    "    \n",
    "    return model1, model2, model3, model4, model5, model6, model7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f1a2b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive_bayes: 0.89 \n",
      "kneighbors: 0.86\n",
      "LogisticRegression: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\latefallsapp\\Anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest: 0.92\n",
      "DecisionTree: 0.86\n",
      "GradientBoost: 0.89\n",
      "SVM: 0.86\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MultinomialNB(),\n",
       " KNeighborsClassifier(),\n",
       " LogisticRegression(),\n",
       " RandomForestClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " GradientBoostingClassifier(),\n",
       " SVC())"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models(X_train_ct, X_test_ct, y_train_ct, y_test_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f331f6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive_bayes: 0.92 \n",
      "kneighbors: 0.88\n",
      "LogisticRegression: 0.92\n",
      "RandomForest: 0.93\n",
      "DecisionTree: 0.87\n",
      "GradientBoost: 0.92\n",
      "SVM: 0.92\n"
     ]
    }
   ],
   "source": [
    "model1, _, model3, model4, _, model6, model7 = test_models(X_train_tf, X_test_tf, y_train_tf, y_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b6c5607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9290465631929047"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = []\n",
    "# models.append(('naive_bayer', model1))\n",
    "models.append(('LogisticRegression', model3))\n",
    "models.append(('RandomForest', model4))\n",
    "models.append(('GradientBoost', model6))\n",
    "# models.append(('SVM', model7))\n",
    "\n",
    "vote = VotingClassifier(estimators=models, voting='hard')\n",
    "vote.fit(X_train_tf, y_train_tf)\n",
    "vote.score(X_test_tf, y_test_tf)\n",
    "\n",
    "\n",
    "# for model, model_name in zip([model1, model3, model4, model6, model7, vote], ['naive_bayer', 'LogisticRegression', 'RandomForest', 'GradientBoost','SVM', 'vote']):\n",
    "#     score = cross_val_score(model, X_count.toarray(), pd_data.target.values, scoring='accuracy')\n",
    "#     print('{} accuracy: {}'.format(model_name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d090ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06201a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622c09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db5232b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "\n",
    "MAX_HREF_NUM = 50\n",
    "\n",
    "def predict_url(model, url):\n",
    "    response = requests.get(url, timeout=5)\n",
    "    print(response.text)\n",
    "    response.encoding = response.apparent_encoding\n",
    "    html = etree.HTML(response.text)\n",
    "    if html is None:\n",
    "        print('Request Failed')\n",
    "    html_data = html.xpath('//*[@href]/text()')  # 只选取“带有链接”的文本\n",
    "    if len(html_data) >= MAX_HREF_NUM:  # 只选取前多少个带有链接的文本\n",
    "        html_data = html_data[:MAX_HREF_NUM]\n",
    "        \n",
    "    one_item = ''\n",
    "    for item in html_data:\n",
    "        item = item.strip()\n",
    "        one_item += ' '\n",
    "        one_item += item\n",
    "    \n",
    "    item_text = []\n",
    "    text = [i for i in one_item.split()]\n",
    "    for i in text:\n",
    "        for j in jieba.cut(i, cut_all=False):\n",
    "            item_text.append(j)\n",
    "    item_text = ' '.join(item_text)\n",
    "    out= []\n",
    "    out.append(item_text)\n",
    "    out = np.array(out).reshape(-1,)\n",
    "    out_tf = tfidf.transform(out).toarray()\n",
    "    result = model.predict(out_tf)[0]\n",
    "    return int(result)\n",
    "    \n",
    "def predict_file(model, path):\n",
    "    with open(path, 'rb') as f:\n",
    "        results = f.read()\n",
    "        html = etree.HTML(results)\n",
    "        if html is None:\n",
    "            print('Request Failed')\n",
    "            return 0\n",
    "        html_data = html.xpath('//*[@href]/text()')\n",
    "        if len(html_data) >= MAX_HREF_NUM:  # 只选取前多少个带有链接的文本\n",
    "            html_data = html_data[:MAX_HREF_NUM]\n",
    "            \n",
    "    one_item = ''\n",
    "        \n",
    "    for item in html_data:\n",
    "        item = item.strip()\n",
    "        one_item += ' '\n",
    "        one_item += item\n",
    "    \n",
    "    item_text = []\n",
    "    text = [i for i in one_item.split()]\n",
    "    for i in text:\n",
    "        for j in jieba.cut(i, cut_all=False):\n",
    "            item_text.append(j)\n",
    "    item_text = ' '.join(item_text)\n",
    "    out= []\n",
    "    out.append(item_text)\n",
    "    out = np.array(out).reshape(-1,)\n",
    "    out_tf = tfidf.transform(out).toarray()\n",
    "    result = model.predict(out_tf)\n",
    "    return int(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33529ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "957\n",
      "178\n",
      "0.18599791013584116\n",
      "Request Failed\n",
      "1469\n",
      "53\n",
      "0.03607896528250511\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path_pms = '../splashHtmlCrawler/html/pms'\n",
    "files_pms = os.listdir(file_path_pms)\n",
    "num = 0\n",
    "for file in files_pms:\n",
    "    file_name = os.path.join(file_path_pms, file)\n",
    "    result = predict_file(vote, file_name)\n",
    "    if result == 0:\n",
    "        num += 1\n",
    "print(len(files_pms))\n",
    "print(num)\n",
    "print(num/len(files_pms))\n",
    "\n",
    "file_path_pms = '../splashHtmlCrawler/html/notpms'\n",
    "files_pms = os.listdir(file_path_pms)\n",
    "num = 0\n",
    "for file in files_pms:\n",
    "    file_name = os.path.join(file_path_pms, file)\n",
    "    result = predict_file(vote, file_name)\n",
    "    if result == 1:\n",
    "        num += 1\n",
    "print(len(files_pms))\n",
    "print(num)\n",
    "print(num/len(files_pms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98401f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
