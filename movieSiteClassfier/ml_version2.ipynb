{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0204464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000.host</td>\n",
       "      <td>1</td>\n",
       "      <td>资源库-资源分享论坛                               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00ysw.com</td>\n",
       "      <td>1</td>\n",
       "      <td>人人影视 - 在线免费高清电影！                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xo.net</td>\n",
       "      <td>1</td>\n",
       "      <td>异星灾变 第一季 1080p BT网盘下载 Raised by Wolve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100161.com</td>\n",
       "      <td>1</td>\n",
       "      <td>最新免费在线电影-神马电影网-飘花影院-青苹果影院-6080-新视觉影院-策驰影院-神马影...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100fyy.net</td>\n",
       "      <td>1</td>\n",
       "      <td>免费电影_免费电视剧_免费动画片在线观看 - 100分影院        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2432</th>\n",
       "      <td>zqb.cyol.com</td>\n",
       "      <td>0</td>\n",
       "      <td>BT即将启动合法电影下载网站                中青在线 ：    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433</th>\n",
       "      <td>zsb.cucn.edu.cn</td>\n",
       "      <td>0</td>\n",
       "      <td>电影学(院线管理)                         ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>zw.liuxue86.com</td>\n",
       "      <td>0</td>\n",
       "      <td>九月最值得期待的院线电影|电影评论                  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>zy3.xidian.edu.cn</td>\n",
       "      <td>0</td>\n",
       "      <td>挑灯寻影|阿竹影院首映场完美结束！精彩影评与下期预告同时奉上~-西安电子科技大学竹园...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>zyyjy.bucm.edu.cn</td>\n",
       "      <td>0</td>\n",
       "      <td>中医药教育网                  首页   组织机构    新闻动...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2437 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 domain  target  \\\n",
       "0            00000.host       1   \n",
       "1             00ysw.com       1   \n",
       "2               0xo.net       1   \n",
       "3            100161.com       1   \n",
       "4            100fyy.net       1   \n",
       "...                 ...     ...   \n",
       "2432       zqb.cyol.com       0   \n",
       "2433    zsb.cucn.edu.cn       0   \n",
       "2434    zw.liuxue86.com       0   \n",
       "2435  zy3.xidian.edu.cn       0   \n",
       "2436  zyyjy.bucm.edu.cn       0   \n",
       "\n",
       "                                                   text  \n",
       "0          资源库-资源分享论坛                               ...  \n",
       "1        人人影视 - 在线免费高清电影！                           ...  \n",
       "2              异星灾变 第一季 1080p BT网盘下载 Raised by Wolve...  \n",
       "3      最新免费在线电影-神马电影网-飘花影院-青苹果影院-6080-新视觉影院-策驰影院-神马影...  \n",
       "4              免费电影_免费电视剧_免费动画片在线观看 - 100分影院        ...  \n",
       "...                                                 ...  \n",
       "2432        BT即将启动合法电影下载网站                中青在线 ：    ...  \n",
       "2433              电影学(院线管理)                         ...  \n",
       "2434             九月最值得期待的院线电影|电影评论                  ...  \n",
       "2435      挑灯寻影|阿竹影院首映场完美结束！精彩影评与下期预告同时奉上~-西安电子科技大学竹园...  \n",
       "2436        中医药教育网                  首页   组织机构    新闻动...  \n",
       "\n",
       "[2437 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd_data = pd.read_csv('./movie_raw_data.csv', index_col=0)\n",
    "pd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4478ab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\晚秋\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.687 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "# 这段代码是把上面dataframe的text部分进行分词，然后转到列表里面去，方便进行tf-idf，结果可以看下面\n",
    "all_text = []\n",
    "for index in pd_data.index:\n",
    "    item_text = []\n",
    "    text = pd_data.iloc[index, 2]\n",
    "    text = [i for i in text.split()]\n",
    "    for i in text:\n",
    "        for j in jieba.cut(i, cut_all=False):\n",
    "            item_text.append(j)\n",
    "    item_text = ' '.join(item_text)\n",
    "    all_text.append(item_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a619fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['资源库 - 资源 分享 论坛 搜索 仅 搜索 标题 作者 ： 搜索 高级 搜索 ... 仅 搜索 标题 作者 ： 搜索 Advanced ... 登录 注册 搜索 仅 搜索 标题 作者 ： 搜索 高级 搜索 ... 仅 搜索 标题 作者 ： 搜索 Advanced ... Toggle sidebar Toggle sidebar 论坛 列表 菜单 安装 应用 安装 主页 论坛 新帖 搜索 论坛 最新消息 新帖 新 资源 个人 空间信息 最新 动态 下载 中心 最新 评论 搜索 资源 会员 当前 访客 个人 空间信息 搜索 个人 空间信息 资源 盘 Chat 捐 Welcome to our Community Wanting to join the rest of our members ? Feel free to sign up today . Sign up 禁用 JavaScript 。 为了 获得 更好 的 体验 ， 请 在 运行 之前 启用 浏览器 中 的 JavaScript 。 您 正在 使用 一款 已经 过时 的 浏览器 ！ 部分 功能 不能 正常 使用 。 请 尝试 升级 或 使用 其他 浏览器 。 用户 交流 求助 问答 ， 沟通 你 我 闲聊 灌水 新 20 56 主题 20 消息 56 关 论坛 那个 网盘 注册 送 1T ？ 星期一 ， 16 : 03 关键时刻 119 求助 问答 新 3 7 主题 3 消息 7 网站 建议 2022 / 02 / 10 yemo1408 影视 分享 热门 电影 新 154 197 主题 154 消息 197 Q 反贪 风暴 5 ( 2021 ) 今天 11 : 09 q134182528 热门 剧集 新 115 118 主题 115 消息 118 Q 维京 传奇 ： 英灵 神殿 昨天 19 : 19 q134182528 寻觅 影视 新 3 8 主题 3 消息 8 扑 求 “ 不二 神探 ” 电影 ， 磁力 下 不了 ， 有没有 保存 了 的 兄弟 哦 2022 / 02 / 12 扑克 脸 软件 分享 电脑软件 新 47 72 主题 47 消息 72 Windows 微软 电脑 管家 内测 版 星期二 ， 23 : 00 admin 手机软件 新 29 69 主题 29 消息 69 TikTok - 去 广告 解除 封锁 版 昨天 23 : 10 lzhouh 源码 分享 WordPress 主题 新 6 9 资源库 资源库 资源库 - 资源共享 大全 , 通过 网盘 分享 、 磁力 链接 下载 、 迅雷 下载 、 电驴 资源 下载 、 BT 种子 下载 分享 电影 、 电视剧 、 无损 音乐 、 教程 、 素材 、 图书 、 游戏 等 资源 。 资源库 - 资源共享 大全 , 通过 网盘 分享 、 磁力 链接 下载 、 迅雷 下载 、 电驴 资源 下载 、 BT 种子 下载 分享 电影 、 电视剧 、 无损 音乐 、 教程 、 素材 、 图书 、 游戏 等 资源 。 资源库 - 资源共享 大全 , 通过 网盘 分享 、 磁力 链接 下载 、 迅雷 下载 、 电驴 资源 下载 、 BT 种子 下载 分享 电影 、 电视剧 、 无损 音乐 、 教程 、 素材 、 图书 、 游戏 等 资源 。 资源库 - 资源 分享 论坛 资源库 - 资源 分享 论坛 资源库 - 资源 分享 论坛',\n",
       " '人人 影视 - 在线 免费 高清 电影 ！ 微信 扫码 观看 今日 更新 “ 0 ” 部 影片 首页 电影 连续剧 综艺 动漫 更 多 > 动作片 喜剧片 爱情片 科幻片 恐怖片 剧情片 战争片 最新 电影 HD 谤 法 ： 在 此 矣 超清 幸存者 1937 HD 恐惧 街 2021 HD 切勿 擅动 HD 陌生人 的 善意 2019 HD 第八天 之夜 超清 绝地 狙杀 HD 午夜 2021 HD 杀手 妻子 的 保镖 HD 冥通 银行 特约 ： 翻生 争霸战 HD 盖亚 2021 HD 完美 敌人 2020 更 多 > 泰国 剧 国产 剧 港台剧 日韩剧 欧美 剧 最新 连续剧 共 6 集 , 完结 男 文案 撰稿人 ， 要休 育儿 假 更新 至 06 集 我 的 妄想 饭 想得到 夸奖 共 12 集 , 更新 至 7 集 智子 和 知子 共 11 集 , 更新 至 7 集 夏日 幽会 共 43 集 , 更新 至 28 集 玉楼春 共 38 集 , 更新 至 28 集 逐梦 蓝天 共 6 集 , 更新 至 第 3 集 演绎 屋 更新 至 11 集 亲爱 的 爸妈 更新 至 14 集 与 君歌 卫视 版 共 5 集 , 更新 至 4 集 黑 天鹅湖 更新 至 30 集 大時代 国语 更新 至 28 集 他來 自 江湖 国语 更 多 > 最新 综艺 更新 至 20210814 期 我们 爱上 的 那首歌 ， 新 歌手 更新 至 20210814 期 明星 许愿池 更新 至 20210701 期 说 Vival 更新 至 20210702 期 换乘 恋爱 更新 至 20210702 期 白种 元 的 国名 饮食 更新 至 20210702 期 第六感 第二季 更新 至 20210703 期 做 家务 的 男人 们 第二季 更新 至 20210703 期 LOUD 更新 至 20210705 期 超级 乐队 2 更新 至 20210706 期 期盼 已久 的 大海 更新 至 20210608 期 赤裸 的 世界史 更新 至 20210523 期 喜剧 大 联盟 2021 更 多 > 最新 动漫 更新 至 03 集 魔 道 祖师 第三季 更新 至 15 集 逆天 至尊 更新 至 03 集 魔 道 祖师 第一季 日语 版 更新 至 04 集 九九八十一 更新 至 18 集 时空 恋人 更新 至 20 集 重生 相逢 ： 给 你 我 的 独家 宠溺 更新 至 15 集 龙王 殿 更新 至 23 集 逆天 邪神 第二季 更新 至 15 集 前无古人 更新 至 13 集 绝世 武神 第三季 更新 至 第 3 集 元龙 第二季 更新 至 12 集 酷 大叔 的 恋爱 物语 友情链接 百度 云 影视 杰哥 影视 我 爱 影视 秋秋 影视 全能 影视 人人 影视 返回 首页 返回 顶部 Copyright © 2011 - 2018 maccms . [ 苹果 电影 程序 ] 版权所有 Copyright © 2008 - 2018 免费 , 电影 , 视频 大全 , 在线 高清 电影 , 付费 电影 , 免费电影 , 剧集 , 电影 , VIP 高清 电影 直播 , 免费 看 , 人人 影视 , 在线 追剧 人人 影视 是 专门 做 剧集 , 电影 等 服务 ， 本 页面 提供 电影 的 相关 内容 , 提供 最新 最快 的 影视资讯 。']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70dd58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 80\n",
    "# 80 : 93.4%\n",
    "# 90 : 93.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebad20ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02\n",
      "10\n",
      "11\n",
      "12\n",
      "16\n",
      "20\n",
      "2021\n",
      "2022\n",
      "the\n",
      "下载\n",
      "分享\n",
      "影视\n",
      "最新\n",
      "游戏\n",
      "热门\n",
      "电影\n",
      "电视剧\n",
      "网站\n",
      "资源\n",
      "软件\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=10, max_features=MAX_FEATURES)\n",
    "X_tfidf = tfidf.fit_transform(all_text)\n",
    "X_labels =X_tfidf.toarray() > 0\n",
    "features = tfidf.get_feature_names_out()\n",
    "for index in range(len(X_labels[0])):\n",
    "    if X_labels[0][index] == True:\n",
    "        print(features[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c29bfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '02', '04', '07', '08', '10', '1080p', '11', '12', '13',\n",
       "       '14', '15', '16', '20', '2019', '2020', '2021', '2022', '22', '24',\n",
       "       '25', '26', '30', '4k', 'com', 'hd', 'the', 'www', '一个', '下载',\n",
       "       '中国', '中字', '主演', '免费', '分享', '剧情', '动作', '动漫', '可以', '喜剧', '国产',\n",
       "       '在线', '大陆', '完结', '影片', '影视', '影院', '我们', '手机', '推荐', '提供', '播放',\n",
       "       '新闻', '时间', '更新', '最新', '服务', '欧美', '游戏', '热门', '爱情', '电影', '电影网',\n",
       "       '电视剧', '第一季', '第二季', '类型', '综艺', '网站', '美国', '蓝光', '观看', '视频',\n",
       "       '资源', '超清', '软件', '院线', '集全', '首页', '高清'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0a9bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 2 3]\n",
      " [0 8 0 ... 0 2 0]\n",
      " ...\n",
      " [6 4 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 3 0]\n",
      " [5 0 3 ... 0 1 0]]\n",
      "2437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(max_features=MAX_FEATURES)\n",
    "X_count = count.fit_transform(all_text)\n",
    "print(X_count.toarray())\n",
    "print(len(X_count.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c66e27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '02', '04', '07', '08', '10', '1080p', '11', '12', '13',\n",
       "       '14', '15', '16', '20', '2019', '2020', '2021', '2022', '22', '24',\n",
       "       '25', '26', '30', '4k', 'com', 'hd', 'the', 'www', '一个', '下载',\n",
       "       '中国', '中字', '主演', '免费', '分享', '剧情', '动作', '动漫', '可以', '喜剧', '国产',\n",
       "       '在线', '大陆', '完结', '影片', '影视', '影院', '我们', '手机', '推荐', '提供', '播放',\n",
       "       '新闻', '时间', '更新', '最新', '服务', '欧美', '游戏', '热门', '爱情', '电影', '电影网',\n",
       "       '电视剧', '第一季', '第二季', '类型', '综艺', '网站', '美国', '蓝光', '观看', '视频',\n",
       "       '资源', '超清', '软件', '院线', '集全', '首页', '高清'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a415efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(X_tfidf.toarray(), pd_data.target.values, test_size=0.2)\n",
    "X_train_ct, X_test_ct, y_train_ct, y_test_ct = train_test_split(X_count.toarray(), pd_data.target.values, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0822b72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\latefallsapp\\Anaconda\\envs\\d2l\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def test_models(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "#     if method == 'tfidf':\n",
    "#         X_train = tfidf.transform(X_train)\n",
    "#         X_test = tfidf.transform(X_test)\n",
    "#     elif method == 'count':\n",
    "#         X_train = count.transform(X_train)\n",
    "#         X_test = count.transform(X_test)\n",
    "\n",
    "    model1 = MultinomialNB()\n",
    "    model1.fit(X_train, y_train)\n",
    "    print('Naive_bayes: {:.2f} '.format(model1.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "\n",
    "    model2 = KNeighborsClassifier()\n",
    "    model2.fit(X_train, y_train)\n",
    "    print('kneighbors: {:.2f}'.format(model2.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "    model3 = LogisticRegression()\n",
    "    model3.fit(X_train, y_train)\n",
    "    print('LogisticRegression: {:.2f}'.format(model3.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "    model4 = RandomForestClassifier()\n",
    "    model4.fit(X_train, y_train)\n",
    "    print('RandomForest: {:.2f}'.format(model4.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "    model5 = DecisionTreeClassifier()\n",
    "    model5.fit(X_train, y_train)\n",
    "    print('DecisionTree: {:.2f}'.format(model5.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "    model6 = GradientBoostingClassifier()\n",
    "    model6.fit(X_train, y_train)\n",
    "    print('GradientBoost: {:.2f}'.format(model6.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "    model7 = SVC(kernel='rbf')\n",
    "    model7.fit(X_train, y_train)\n",
    "    print('SVM: {:.2f}'.format(model7.score(X_test, y_test)))\n",
    "    \n",
    "    \n",
    "    model8 = XGBClassifier()\n",
    "    model8.fit(X_train, y_train)\n",
    "    print('xgboost: {:.2f}'.format(model8.score(X_test, y_test)))\n",
    "    \n",
    "    return model1, model2, model3, model4, model5, model6, model7, model8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e36bd904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive_bayes: 0.89 \n",
      "kneighbors: 0.87\n",
      "LogisticRegression: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\latefallsapp\\Anaconda\\envs\\d2l\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest: 0.92\n",
      "DecisionTree: 0.84\n",
      "GradientBoost: 0.91\n",
      "SVM: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\latefallsapp\\Anaconda\\envs\\d2l\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:16:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xgboost: 0.92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MultinomialNB(),\n",
       " KNeighborsClassifier(),\n",
       " LogisticRegression(),\n",
       " RandomForestClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " GradientBoostingClassifier(),\n",
       " SVC(),\n",
       " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "               gamma=0, gpu_id=-1, importance_type=None,\n",
       "               interaction_constraints='', learning_rate=0.300000012,\n",
       "               max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "               monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "               num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "               tree_method='exact', validate_parameters=1, verbosity=None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models(X_train_ct, X_test_ct, y_train_ct, y_test_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d2d4778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive_bayes: 0.89 \n",
      "kneighbors: 0.89\n",
      "LogisticRegression: 0.90\n",
      "RandomForest: 0.91\n",
      "DecisionTree: 0.87\n",
      "GradientBoost: 0.92\n",
      "SVM: 0.91\n",
      "[18:16:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\latefallsapp\\Anaconda\\envs\\d2l\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost: 0.91\n"
     ]
    }
   ],
   "source": [
    "model1, _, model3, model4, _, model6, model7, model8 = test_models(X_train_tf, X_test_tf, y_train_tf, y_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cea4b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\latefallsapp\\Anaconda\\envs\\d2l\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:16:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9139344262295082"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = []\n",
    "# models.append(('naive_bayer', model1))\n",
    "models.append(('LogisticRegression', model3))\n",
    "models.append(('RandomForest', model4))\n",
    "models.append(('GradientBoost', model6))\n",
    "models.append(('XgBoost', model8))\n",
    "# models.append(('SVM', model7))\n",
    "\n",
    "vote = VotingClassifier(estimators=models, voting='hard')\n",
    "vote.fit(X_train_tf, y_train_tf)\n",
    "vote.score(X_test_tf, y_test_tf)\n",
    "\n",
    "\n",
    "# for model, model_name in zip([model1, model3, model4, model6, model7, vote], ['naive_bayer', 'LogisticRegression', 'RandomForest', 'GradientBoost','SVM', 'vote']):\n",
    "#     score = cross_val_score(model, X_count.toarray(), pd_data.target.values, scoring='accuracy')\n",
    "#     print('{} accuracy: {}'.format(model_name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ecbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e584ab8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79857b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1813739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "import chardet\n",
    "\n",
    "MAX_HREF_NUM = 1000\n",
    "\n",
    "def predict_url(model, url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "    except:\n",
    "        return False\n",
    "    response.encoding = response.apparent_encoding\n",
    "    html = etree.HTML(response.text)\n",
    "    if html is None:\n",
    "        print('Request Failed')\n",
    "        return False\n",
    "#     html_data = html.xpath('//*[@href]/text()')  # 只选取“带有链接”的文本\n",
    "    html_data = html.xpath('//*[name(.)!=\"style\" and name(.)!=\"script\"]/text()')\n",
    "    if len(html_data) >= MAX_HREF_NUM:  # 只选取前多少个带有链接的文本\n",
    "        html_data = html_data[:MAX_HREF_NUM]\n",
    "        \n",
    "    one_item = ''\n",
    "    for item in html_data:\n",
    "        item = item.strip()\n",
    "        one_item += ' '\n",
    "        one_item += item\n",
    "    \n",
    "    item_text = []\n",
    "    text = [i for i in one_item.split()]\n",
    "    for i in text:\n",
    "        for j in jieba.cut(i, cut_all=False):\n",
    "            item_text.append(j)\n",
    "    item_text = ' '.join(item_text)\n",
    "    out= []\n",
    "    out.append(item_text)\n",
    "    out = np.array(out).reshape(-1,)\n",
    "    out_tf = tfidf.transform(out).toarray()\n",
    "    result = model.predict(out_tf)[0]\n",
    "    return int(result)\n",
    "    \n",
    "def predict_file(model, path):\n",
    "    with open(path, 'rb') as f:\n",
    "        results = f.read()\n",
    "        code = chardet.detect(results)\n",
    "        try:\n",
    "            if code['encoding'] is None:\n",
    "                results = results.decode('utf8')\n",
    "            else:\n",
    "                results = results.decode(code['encoding'])\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                results = results.decode('GB18030')\n",
    "            except UnicodeDecodeError:\n",
    "                try:\n",
    "                    results = results.decode('utf8', errors='ignore')\n",
    "                except:\n",
    "                    print('file: {}, code: {}'.format(file, code))\n",
    "                    print('Not valid encode.')\n",
    "                    return False\n",
    "        html = etree.HTML(results)\n",
    "        if html is None:\n",
    "            print('Request Failed')\n",
    "            return 0\n",
    "#         html_data = html.xpath('//*[@href]/text()')\n",
    "        html_data = html.xpath('//*[name(.)!=\"style\" and name(.)!=\"script\"]/text()')\n",
    "        if len(html_data) >= MAX_HREF_NUM:  # 只选取前多少个带有链接的文本\n",
    "            html_data = html_data[:MAX_HREF_NUM]\n",
    "            \n",
    "    one_item = ''\n",
    "        \n",
    "    for item in html_data:\n",
    "        item = item.strip()\n",
    "        one_item += ' '\n",
    "        one_item += item\n",
    "    \n",
    "    item_text = []\n",
    "    text = [i for i in one_item.split()]\n",
    "    for i in text:\n",
    "        for j in jieba.cut(i, cut_all=False):\n",
    "            item_text.append(j)\n",
    "    item_text = ' '.join(item_text)\n",
    "    out= []\n",
    "    out.append(item_text)\n",
    "    out = np.array(out).reshape(-1,)\n",
    "    out_tf = tfidf.transform(out).toarray()\n",
    "    result = model.predict(out_tf)\n",
    "    return int(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6e15f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 files has been predicted.\n",
      "200 files has been predicted.\n",
      "300 files has been predicted.\n",
      "400 files has been predicted.\n",
      "500 files has been predicted.\n",
      "600 files has been predicted.\n",
      "700 files has been predicted.\n",
      "800 files has been predicted.\n",
      "900 files has been predicted.\n",
      "968\n",
      "100\n",
      "0.10330578512396695\n",
      "Request Failed\n",
      "1489\n",
      "29\n",
      "0.019476158495634655\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "wrong_postive = []\n",
    "\n",
    "file_path_pms = '../splashHtmlCrawler/html/pms'\n",
    "files_pms = os.listdir(file_path_pms)\n",
    "num = 0\n",
    "for index, file in enumerate(files_pms, 1):\n",
    "    if index % 100 == 0:\n",
    "        print('{} files has been predicted.'.format(index))\n",
    "    file_name = os.path.join(file_path_pms, file)\n",
    "    result = predict_file(vote, file_name)\n",
    "    if result == 0:\n",
    "        num += 1\n",
    "        wrong_postive.append(file)\n",
    "print(len(files_pms))\n",
    "print(num)\n",
    "print(num/len(files_pms))\n",
    "\n",
    "file_path_pms = '../splashHtmlCrawler/html/notpms'\n",
    "files_pms = os.listdir(file_path_pms)\n",
    "num = 0\n",
    "for file in files_pms:\n",
    "    file_name = os.path.join(file_path_pms, file)\n",
    "    result = predict_file(vote, file_name)\n",
    "    if result == 1:\n",
    "        num += 1\n",
    "print(len(files_pms))\n",
    "print(num)\n",
    "print(num/len(files_pms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad269cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong_postive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f43989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf11a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65230298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import numpy as np\n",
    "\n",
    "db = pymysql.connect(\n",
    "    host='1.15.220.155',\n",
    "    user='test',\n",
    "    password='991125',\n",
    "    database='spider',\n",
    "    charset='utf8'\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b7d7212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: http://100fyy.net/, predict_ispms: 1\n",
      "URL: https://100ip.cn/, predict_ispms: 1\n",
      "URL: http://1080fun.vip/78.html, predict_ispms: 1\n",
      "URL: https://115.com/140041/T50711.html, predict_ispms: 1\n",
      "URL: https://115fhd.com/, predict_ispms: 1\n",
      "URL: http://123-bt.cn/, predict_ispms: 1\n",
      "URL: http://1314yy.net/search.php, predict_ispms: 1\n",
      "URL: http://15.woxiedao.com/, predict_ispms: 1\n",
      "URL: https://17.yxq.email/, predict_ispms: 1\n",
      "URL: http://17ky.net/, predict_ispms: 1\n",
      "URL: https://1920i.com/index.php/vod/detail/id/337431.html, predict_ispms: 1\n",
      "URL: https://192link.com/sitetag/50.html, predict_ispms: 1\n",
      "URL: https://1jubt.top/, predict_ispms: 1\n",
      "URL: https://200121.com/, predict_ispms: 1\n",
      "URL: https://23011111.com/, predict_ispms: 1\n",
      "URL: https://2345dy.org/, predict_ispms: 1\n",
      "Request Failed\n",
      "URL: http://258.tv/film/about-time/, predict_ispms: 1\n",
      "URL: http://258.tv/film/her/, predict_ispms: 1\n",
      "URL: http://258.tv/man-on-the-edge-film/, predict_ispms: 1\n",
      "URL: http://2gody.com/vod-detail-id-206491.html, predict_ispms: 1\n",
      "URL: https://360tv.cc/search-pg-107-year-2020-typeid-7-by-time.html, predict_ispms: 1\n",
      "URL: http://37gc.com/, predict_ispms: 1\n",
      "Request Failed\n",
      "URL: https://400mov.com/post/225f83e9ea.html, predict_ispms: 1\n",
      "URL: https://4410ysy.com/, predict_ispms: 1\n",
      "URL: http://4480.tv/, predict_ispms: 1\n",
      "URL: http://4480sb.cc/type/1.html, predict_ispms: 1\n",
      "URL: http://4g.v.sogou.com/movie/mzuwy3k7geztqmbshazasmjzgiyq.html?spver=1, predict_ispms: 1\n",
      "URL: http://4g.v.sogou.com/movie/mzuwy3k7g42dsmjxgme3nyod7td3to7q.html?spver=1, predict_ispms: 1\n",
      "URL: https://4k-m.com/, predict_ispms: 1\n",
      "URL: https://4k-m.com/m/?l=%E7%A7%91%E5%B9%BB&d=%E5%85%A8%E9%83%A8&n=1999, predict_ispms: 1\n",
      "URL: https://4k1080.com/forum-60-1.html, predict_ispms: 1\n",
      "URL: https://4k1080.com/, predict_ispms: 1\n",
      "URL: https://4k1080.com/forum-2-1.html, predict_ispms: 1\n",
      "URL: https://4kdv.com/, predict_ispms: 1\n",
      "URL: http://4kiso.com/, predict_ispms: 1\n",
      "URL: https://4kwu.net/, predict_ispms: 1\n",
      "URL: https://4kwu.net/ys/lingmei.html, predict_ispms: 1\n",
      "URL: http://51xdy.cn/, predict_ispms: 1\n",
      "URL: http://521080p.com/78.html, predict_ispms: 1\n",
      "URL: https://558cq.com/, predict_ispms: 1\n",
      "URL: http://581bo.net/, predict_ispms: 1\n",
      "URL: http://585.tv/, predict_ispms: 1\n",
      "URL: https://58vod.com/, predict_ispms: 1\n",
      "URL: http://6080svip.com/, predict_ispms: 1\n",
      "URL: https://6688.in/, predict_ispms: 1\n",
      "URL: http://6868o.com/vodplay/68800-1-1.html, predict_ispms: 1\n",
      "URL: http://6868o.com/, predict_ispms: 1\n",
      "URL: http://68mv.com/, predict_ispms: 1\n",
      "URL: http://70dvd.cc/play/49078-0-4.html, predict_ispms: 1\n",
      "URL: http://70dvd.cc/play/49335-0-0.html, predict_ispms: 1\n",
      "URL: https://789yyw.com/, predict_ispms: 1\n",
      "URL: http://80dytt.cn/list/?1-973.html, predict_ispms: 1\n",
      "URL: http://80s.us/html/movie/list/----g, predict_ispms: 1\n",
      "URL: http://80yy.cn/, predict_ispms: 1\n",
      "URL: https://8666tv.net/dm/108533.html, predict_ispms: 1\n",
      "URL: http://87238.cc/, predict_ispms: 1\n",
      "URL: http://888hhh.com/look/movie27221.html, predict_ispms: 1\n",
      "URL: http://888hhh.com/playid/57217-0-0.html, predict_ispms: 1\n",
      "URL: http://888hhh.com/, predict_ispms: 1\n",
      "URL: https://8yunpan.com/forum.php?gid=56, predict_ispms: 1\n",
      "URL: https://913543.com/, predict_ispms: 1\n",
      "URL: https://91diany.com/vod-type8/--2020---hits-40.html, predict_ispms: 1\n",
      "URL: https://923r.cn/vodplay/109991-1-1.html, predict_ispms: 1\n",
      "URL: http://9520tv.com/, predict_ispms: 1\n",
      "URL: https://97lldy.com/3ji/38258.html, predict_ispms: 1\n",
      "URL: https://9ela.com/, predict_ispms: 1\n",
      "URL: https://9kdyw.com/play/89728-1-1.html, predict_ispms: 1\n",
      "Request Failed\n",
      "Request Failed\n",
      "Request Failed\n",
      "Request Failed\n",
      "Request Failed\n",
      "URL: http://abad36.com/, predict_ispms: 1\n",
      "URL: https://aidi.tv/play/2417-1-1.html, predict_ispms: 1\n",
      "URL: http://aidi.tv/, predict_ispms: 1\n",
      "URL: https://aidi.tv/movie/67.html, predict_ispms: 1\n",
      "URL: https://aidi.tv/show/dianying-%E6%B3%B0%E5%9B%BD--%C3%A6%C2%81%C2%90%C3%A6%E2%82%AC%E2%80%93--d------2020.html, predict_ispms: 1\n",
      "URL: https://aidi.tv/v/dianying.html, predict_ispms: 1\n",
      "URL: https://aidi.tv/play/2411-1-1.html, predict_ispms: 1\n",
      "URL: https://aidi.tv/play/2422-1-1.html, predict_ispms: 1\n",
      "URL: https://aidi.tv/play/2429-1-1.html, predict_ispms: 1\n",
      "URL: http://ailiemei.com/, predict_ispms: 1\n",
      "URL: http://aishiw.com/, predict_ispms: 1\n",
      "Request Failed\n",
      "URL: https://aiyingshis.com/voddetail/157611.html, predict_ispms: 1\n",
      "Request Failed\n",
      "URL: https://akdy.com/, predict_ispms: 1\n",
      "URL: https://all.wasu.cn/index/sort/time/cid/4/area/4/typestr/%E6%88%98%E4%BA%89/class/program, predict_ispms: 1\n",
      "Request Failed\n",
      "Request Failed\n",
      "Request Failed\n",
      "Request Failed\n",
      "Request Failed\n",
      "URL: http://anltv.cn/index.php/vod/detail/id/56649.html, predict_ispms: 1\n",
      "URL: http://anxcw88.cn/category.php?category=1138&display=grid&brand=0&price_min=0&price_max=0&filter_attr=0&page=1&sort=sales_volume&order=DESC, predict_ispms: 1\n"
     ]
    }
   ],
   "source": [
    "c = db.cursor()\n",
    "c.execute('select distinct(url) from results where isPMS is NULL')\n",
    "results = list(c.fetchall())\n",
    "for i in range(500):\n",
    "    out = predict_url(vote, results[i][0])\n",
    "    if out == 1:\n",
    "        print('URL: {}, predict_ispms: {}'.format(results[i][0], out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c5ced876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_website.pkl']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "joblib.dump(vote, 'movie_website.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "761ddd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9139344262295082"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model = joblib.load('movie_website.pkl')\n",
    "save_model.score(X_test_tf, y_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4de8ad9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tf-idf.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidf, 'tf-idf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a7a24635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=80, min_df=10)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_tf = joblib.load('tf-idf.pkl')\n",
    "save_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ead1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
